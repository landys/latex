\chapter{基于SVM的中文文本分类技术}
\label{cha:study}

\section{中文文本分类技术概述}
\label{sec:studySummary}

目前典型的中文文本分类技术过程如图\ref{fig:textClassify}:

\begin{figure}[h]\centering
  \wuhao
  \includegraphics[width=0.70\textwidth]{textClassify.eps}
  \caption{自动文本分类过程\cite{gaojie04}}\label{fig:textClassify}
\end{figure}

该技术详细步骤如下：

\begin{compactenum}
\item
准备测试集文本；
\item
测试集文本人工分成若干类别；
\item
利用词典进行文本分词；
\item
去停用词、合并数字人名，进行一定的降维；
\item
采用TF-IDF公式计算词条权重；
\item
特征项抽取（利用互信息量、词熵、X2 统计量等方法）；
\item
特征降维处理，方法有主成分分析、潜在语义标引、非负矩阵分解）；
\item
构造分类器（比如SVM、向量距离分类法、KNN算法、贝叶斯算法等）；
\item
用特征词汇描述测试文本；
\item
取部分测试文本用来训练分类器，另一部分测试，并根据结果进行一些改进和优化；
\item
利用训练好的分类器对新文本进行分类。
\end{compactenum}

在该技术中，所使用的关键技术主要包括倒排索引建立（包括中文分词）、特征向量提取和SVM中文文本分类。

\section{关键技术分折}
\label{sec:studyKeyTech}

\subsection{倒排索引建立}
\label{sec:studyInverse}

倒排索引文件的建立，为特征向量提取提供必要的数据结构。在建立倒排索引文件之前，
需要对中文文本进行分词。

所谓的中文分词是一种将连续的汉语文本序列按一定规则拆分为具有独立语义的词组的过程。\cite{gaojie04}
中文分词是当前分词技术中的一种，分词技术从语言文本结构上来讲大致有两类：
一类以英文为代表的西方语言文本，其文本中的词组以空格作为自然间隔，
从语义准确性及技术复杂度来讲都比较简单。另一类是以汉语为代表的东亚语言文本，
由于文本是由连续文字组成，缺乏有效的间隔，虽有句、段分隔，但在进行机器语言学习、
文本语义理解分析过程中都需以词组为最小单位。因此东亚文本语言实现分词技术相对西方文本语言来讲，
更加的复杂和困难。

在实际的中文分词中，可以根据一些分隔词（Stop
Words），对文本进行分词，得到一个中文词语的列表。
在得到分词结果之后，要对分词的结果列表进行处理，
主要是去掉文本中对分类无用的词语，如叹词，助词等，去掉停用词（stop
word）和标点符号，合并数字人名等，
同时获得保留下来的词语的词频。经过这些处理之后的词语列表，就为创建倒排文件做好了准备。

在文本分类中创建倒排索引文件是为了提高提取特征向量和计算特征向量权重的效率。
因为在倒排索引文件中可以在O(1)时间复杂度下提供对特征向量选择，特征权重计算所需要的重要变量值，
如每一个关键词的总词频和文件词频，出现某个特征向量的文件的个数等。

\subsection{特征向量提取}
\label{sec:studyFeature}
特征向量提取过程主要是把中文文本转化成用特征向量权重表示的文件，便于SVM对文本进行分类。
而特征向量的维在文本分类中是指在文本中出现，可以标识文本所属类别的词语。
特征向量提取过程可以分为特征抽取和生成文本特征向量。

特征的抽取一般是通过构造一个特征评分函数，把测量空间的数据（分词词语）投影到特征空间，
得到在特征空间中的值，然后根据这个值对每个特征进行评估，特征选择就成了选择值最高的若干个特征\cite{David92,Yiming97}。

选择合适的特征评分函数也是文本分类的一个关键内容。在中文文本分类中，
常用的特征评分函数主要有如下几种\cite{qin03}：

\begin{compactitem}
\item
词条和类别的互信息。词条和类别的互信息体现了词条和类别的相关程度，互信息越大，词条和类别的相关程度也越大。
\item
词条的X统计。词条的X统计比较了词条对一个类别的贡献和对其余类别的贡献的大小，
以及词条和其余词条对分类的影响。
\item
词条的期望交叉熵。交叉熵反映了文本类别的概率分布和在出现了某
个特定词的条件下文本类别的概率分布之间的距离，词条的交叉熵越大，对文本类别分布的影响也越大。
\item
文本证据权。它比较了类出现的概率和在给定特征下类出现的条件概率之间的差别。
\item
信息增益。它和期望交叉熵不同之处仅在于它还考虑了词条未出现的情况。
\end{compactitem}


特征抽取成功之后，把文本表示成文本特征向量一般分为两步：
\begin{compactenum}
\item
计算每个词条在各个类别中的互信息量。
\item
依次抽取每个类别中互信息量最大并且不在特征集合中的词，加入到特征集合中。
\end{compactenum}

这两个步骤不断迭代抽取，直到抽取的特征个数等于用户配置的最大特征个数或者抽取了所有特征为止。

事实上，把文本表示成文本特征向量就是把中文文本转化成可以被SVM分类器识别的特征权重表示。
对于文本来说，计算权重常采用TF*IDF技术实现。这样，一般地生成过程为：

首先将要分类的文本进行分词，然后判断每一个词语是否属于特征向量，
如果这个词语属于特征向量的一个维度，
就计算的它的TF*IDF的值作为它的特征向量权重。整个过程如图\ref{fig:textTrans}:
\begin{figure}[h]\centering
  \wuhao
  \includegraphics[width=0.40\textwidth]{textTrans.eps}
  \caption{文本转化过程}\label{fig:textTrans}
\end{figure}

\subsection{基于SVM中文文本分类}
\label{sec:studySVM}

把文本表示成文本特征向量之后，就可以使用SVM进行训练和实际分类了。
文本特征向量代表了一个文本，同时能被SVM所识别，它相当于实际文本和SVM之间的媒介。
具体的分类过程如图\ref{fig:svmClassify}：
\begin{figure}[h]\centering
  \wuhao
  \includegraphics[width=0.80\textwidth]{svmClassify.eps}
  \caption{基于SVM中文文本分类器分类过程}\label{fig:svmClassify}
\end{figure}

\section{技术评价}
基于SVM的中文文本分类技术，与其它同样功能的分类技术相比，表现出了优秀的推广性能。
并且SVM正在不断地发展中\cite{Liu06,xuewen06}，包括块算法、固定工作样本集、序列优化思想等不断融入到SVM中，
这也促进了基于SVM的中文文本分类技术的发展。

不过该技术在计算上存在着一些问题，包括训练算法速度慢、算法复杂而难以实现、及分类运算量大等。
使用SVM进行中文文本分类，速度慢的原因主要在于：
\begin{compactitem}
\item
SVM方法需要计算和存储核函数矩阵，当样本点数较大时，需要很大的内存。
\item
SVM在二次型寻优过程中要进行大量的矩阵运算，多数情况下，寻优算法是占用算法时间的主要部分。
\end{compactitem}

另外，中文分词的技术效果，也是中文文本分类的关键。
