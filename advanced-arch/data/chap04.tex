\chapter{粗粒度并行软件方法}
\label{cha:coarse}

\section{简介}
\label{sec:coarseIntro}

粗粒度并行软件方法一般指针对线程级（TLP）及以上并行的软件方法。它往往无需相应硬件技术、体系架构等的支持，
具有良好的可移植性。粗粒度并行软件方法发展较细粒度并行软件方法晚得多，它是随着多核技术的发展而发展，其应用也不成熟。
不过粗粒度并行软件方法明显更适合于多核技术。它能在高层次利用多核的并行性，这样，它就可以忽略一些底层的依赖、同步，
提高性能；并且，粗粒度的并行也意味着更大的灵活性、可测性和伸缩性。

目前粗粒度并行软件方法主要包括两类：基于流语言的软件流水和线程级投机软件流水。本章正是分别探讨这两类软件方法，
并分别从两类方法中的典型实现入手，以对它们有个清晰具体的认识。



\section{基于流语言的软件流水}
\label{sec:coarseStream}

多核已经成为了处理器设计的工业标准，而传统语言如C、C++、FORTRAN等并不适应多核环境，
因为它们都是单指令流和单内存的。这造成了多核资源和优势无法被很好地应用。
而依靠编译器来解决这个问题又是极其困难的，因为目前的编译器并不能很好地实现多核上粗粒度的并行。
而有一类语言――流语言（Stream
Language），因为其并行的特性，却能够较好地应用在多核体系中。

实际上，流语言最早被设计出来，并不是为了支持多核技术。它在很多应用程序领域，如网络，图像,
声音和多媒体等，得到了广泛的应用。但是流语言高层次粗粒度的并行性设计与多核提供的并发性能够天然地结合在一起，
它们的结合是不可避免的。这也揭示出流语言应用于多核领域的一个核心的问题：怎么把流语言中丰富的并行性映射到多核体系结构中去？
因为在结合这种并行性的同时,
常常同时带来通讯和同步开销，并且现实的应用程序中的每一条流程常常是不等价的，存在着一条关键流程。
这诸多问题若不能很好的解决，两者的结合甚至得不偿失。

\subsection{流语言}
\label{sub:coarseStrlan}

流语言最大的特性在于它的并行性。流语言的并行性主要可分为三类\cite{Gordon06}：

\begin{description}
\item[任务并行（Task Parallelism）]：

存在于原始流图（Stream Graph）的不同分枝上的执行单元（Actors）之间。
这些执行单元中，任何一个执行单元的输出不会作为另一个执行单元的输入。
在流语言中，任务并行指算法中的逻辑并行。
这样，可以很容易地把任务并行中的各个任务映射到多核发中的各个处理器中,
在任务的端点（开始或结束处）分裂或合并数据流。
任务并行的冲突在于分裂和合并数据流时的通讯和同步。另外,
任务并行的粒度取决于具体的应用（以及开发人员），所以仅仅采用任务并行是不够的。

\item[数据并行（Data Parallelism）]：

存在于一个执行单元中没有依赖关系的不同执行流程之间。这样,
一个无状态的执行单元能够实现无限制的数据并行，这些执行单元的不同实例可以跑在各种计算单元之上。
数据并行很适合于向量机。但在粗粒度的多核发体系架构中，它会引进额外的通讯开销。
以前的数据并行的流架构往往关注于设计一种特殊的针对于这种通讯的存储层次结构。
数据并行的缺点在于容易导致缓存和延迟的增加,
并且不适用于那些有状态的执行单元。

\item[流水线并行（Pipeline Parallelism）]：

应用于在流图中直接相连的生产者和消费者链中。 可以
通过把生产者和消费者集群映射到不同的核中，再在不同的执行单元间使用芯片内互连实现直接通讯,
来实现流水线并行。和数据并行相比,
流水线并行提供更少的延迟和缓存，以及更好的局部性，也没有引入额外的通信,
同时提供了并发执行有状态执行单元对的能力。流水线并行的缺点在于引入了额外的同步,
因为生产者和消费者在执行中必须紧密地藕合在一起。另外,
还必须实现有效的负载均衡机制,
因为流图的吞吐量取决于所有处理器中吞吐量最小的处理器。
\end{description}

目前已经存在大量的流语言，如StreamIt、Brook、SPUR、Cg、Baker和Spidle等。各种流语言都有各自的特点，
对于多核体系结构来说，StreamIt语言是一种比较经典而合适的。本节讨论的一种基于流语言的软件流水也正是基于SteamIt语言。
并且该技术依赖于StreamIt语言的两个特性：filters之间的生产者-消费者关系；整个流图被一个外层循环所包裹。

不妨稍微介绍一下StreamIt语言。

StreamIt语言\cite{Thies02}是致力于高性能流应用的体系架构无关的编程语言。
StreamIt中的Filters对应上文提到的执行单元（Actors）。
Filter中的work函数执行Filter中的每一步。在work中，filter可执行push到输出通道、
pop输入通道、peek输入通道。StreamIt提供三种层次化的原语,
用于组织filters成为流图。这三种原语分别为：Pipeline、Splitjoin、
Feedbackloop（该原语实际中很少使用）。

\subsection{基于StreamIt的软件流水}
\label{sub:coarseStrIt}

简单地说，论文\cite{Gordon06}实现了一个流语言（StreamIt）的编译系统,
把任务并行，数据并行和流水线并行结合在一起，实现了粗粒度并行，在软件编译方面利用了多核的优势，
很大程度地提高了性能。

该编译系统主要实现了两个新的编译技术：

\begin{itemize}
\item
利用数据并行，通过增加流图的粒度来消除通讯开销。增加粒度通过改可能多地熔合执行单元实现。
该技术还利用了任务并行，
如两个平衡的任务并行执行单元只需并行运行在一半的核中。粗略估计，
粗粒度数据并行取得相对单核的9.9倍的加速比，相对任务并行基准的4.4倍的加速比。
\item
利用流水线并行。通过软件流水线技术来并行执行不同迭代中的执行单元，来避免同步机制的缺陷。传统上，
软件流水线技术用于指令级并行。论文利用流编程的强大特性，
把软件流水线技术用于粗粒度的并行。
这有效地移除了流图定态迭代中的执行单元间的所有依赖关系，极大地增加了调度的自由度。
和基于硬件的流水一下，软件流水允许有状态的执行单元并行执行。不过，
软件流水没有同步开销，因为各处理器读写缓存，而不是直接地通讯。粗略估计，
粗粒度的软件流水取得了相对于单核7.7倍的加速比，
相对于任务并行基线的3.4倍的加速比。
\end{itemize}

数据并行在程序中广泛分布。编译系统通过简单地程序分析检测无状态filters。
通过filter分裂，使得初始filter的定态work最终被分裂到splitjoin的组成部分中。
在多核体系架构中，从filter分裂的结果中分发数据是昂贵的。
所以编译系统只分裂那些计算和通信比率大于某个给定域值的filters。
为进一步减轻通信费用，编译系统引进两个新技术：粗化粒度和补充任务并行。

编译系统在把pipeline熔合为一个filter，
再把这个filter分裂成数据并行的splitjoin时，会出现有些pipeline不能被完全的熔合的可能。
因为有些熔合会引进内部状态，但是有状态的filter无法实现数据并行。
所以论文提供的粗化粒度的算法是在保证熔合的结果filter是无状态的前提下，
尽可能地实现熔合。

实际上，即使每个filter都是可数据并行的，也不能把每个filter都分裂到所有核上执行，
因为这样会消除所有的任务级并行，效率反而不高。
一种替代的方案是：保留原始程序中的任务并行，
只引进充分的数据并行到那些空闲的处理器中。这样做的好处是降低了filter
分裂带来的同步开销，同时避免filter分裂过程本身的计算开销。
编译系统设计了一种称之为智能分裂（Judicious Fission）的启发式算法实现。
该算法自底向上地遍历流图，估计总工作开销，以权衡任务并级和filter
分裂之间的平衡。通过粗化粒度和智能分裂，实现了相对于原始分裂策略6.8倍的加速比。

每一时刻，流水线并行的执行单元各自执行各自的迭代，它们之间的数据交互通过队列保存。
这也表明，两个执行单元执行的距离不能太远，否则它们交互的数据保存所需的缓冲会过大。
这样，实际流水线并行在实现解耦每个执行单元的调度机制之外，还要实现限制缓冲区大小的机制。
这可以通过硬件或软件来实现：

\begin{itemize}
\item
粗粒度硬件流水。主要面临两方面性能权衡:
映射连续的filters到一个给定的处理器；以动态、数据驱动的方式执行filters。
前者严重限制了划分的选择条件，从而导致了糟糕的负载平衡;
后者导致通信模式不再静态，以及需要更复杂的流控制机制，
并且动态分发本身也需要开销。
\item
粗粒度软件流水。通过循环前序和定态循环两种调度实现。
粗粒度软件流水好处是可以更自由的线程划分，有利于线程间负载平衡;
避免需求驱动模型的开销。
\end{itemize}

两种流水相比，粗粒度软件流水更灵活。而在程序中已经包含能够被很好的负载平衡的长流水线时，硬件流水往往效率更高。

软件流水算法映射filters到核的方式与传统算法中映射指令到ALUs中相似。
该算法利用了StreamIt语言的一个重要特性：整个流图包裹在一个隐性的外部循环中。
这要求考虑缓存管理和调度中的通讯，
同时映射filters到核的过程与传统软件流水的过程也有所不同。在该方法中，
每个filter读写缓冲，而不是直接通讯，
这需要一个独立的通讯阶段来协调各缓冲中的数据。
映射filters到核的目标是在通讯阶段最小化同步的过程中优化各核间的负载平衡。
可通过两个阶段实现：先优化负载平衡; 再优化布局设计。前者是一个NP完全问题，
采用贪心划分的启发式算法；后者用一个选择性的熔合包裹划分算法实现。

软件流水线与数据并行相比较而言：软件流水线无法降低瓶颈filter；数据并行更易于粗化流图的粒度，
从而减少更多的同步。另一种考虑是软件流水线更依赖于静态工作估计策略的精确性，所以在测试上难以量化其作用。

一个基于StreamIt语言的软件流水实例如图\ref{fig:streamswp}。它图示了任务、数据、流水线这三种并行。

\begin{figure}[h]\centering
  \wuhao
  \includegraphics[width=\textwidth]{streamswp.eps}
  \caption{一个基于StreamIt语言的软件流水实例\cite{Gordon06}}\label{fig:streamswp}
\end{figure}

总的来说，该技术利用流语言特性在多核上实现了粗粒度的并行，并且在体系架构层次上具有良好的移植性。
实际上，通过调整适应filter分裂的计算与通讯的比值，可以更好地适应不同的体系结构。另外，对于一些基本的算法，
如粗化粒度，智能分裂，划分，选择性的熔合等，在很大程度上是体系无关的。


\section{线程级投机软件流水}
\label{sec:coarseSWP}

该类软件流水算法与传统的软件流水算法有点类似，但它所针对是粗粒度并行。通过一些投机算法，
及相应的通讯同步机制，抽取出线程，并把这些线程映射到多核中的不同核中执行。

论文\cite{Douillet07}提供了一种线程级投机软件流水的编译技术，
从程序式语言实现的并行或非并行的非完美循环，
生成一种适应多核体系结构的多线程软件流水调度，并且同时保证必要的同步、
非死锁和非缓冲区溢出，并且在保证原有指令级并行的条件下来实现线程级并行。

该编译技术首先使用了一维软件流水（Single-dimension Software
Pipelining，SSP）技术来实现软件流水\cite{Rong04}。
SSP是受限资源的软件流水方法，
它针对的是单核体系结构中的完美和非完美的循环嵌套问题。 SSP主要有两个优点:
支持嵌套循环中各层的软件流水；它能利用外层循环的ILP或数据局部性。
其局限性在于，它对最外层循环的并行个数受限于有限的处理器资源。如图\ref{fig:ssp}。

\begin{figure}[h]\centering
  \wuhao
  \includegraphics[width=\textwidth]{ssp.eps}
  \caption{SSP例子\cite{Douillet07}}\label{fig:ssp}
\end{figure}

然后通过一种称之为多线程SWP（Multi-Threaded SWP，MTS）的方法，
把嵌套循环中的循环迭代分别映射到多核芯片的每一个核中，实现线程级并行。
每个迭代循环初始化之间会有一定的间隔，而每个迭代的执行则利用了多核的并行实现。
这样多线程的调度则与每个线程的调度无关，在实现了TLP的同时，保留了ILP。
该方法通过共享内存实现通讯，实现了一个基于Lamport's
Clock的轻量级的同步机制，保证了代码的正确性，并实现一个砖瓦机制（Tiling
Mechanism）保证了灵活性，最后保证结果调度无死锁。 MST主要针对于三个目标：
\begin{compactitem}
\item
解决依赖和资源限制问题;
\item
实现一个轻量级同步机制;
\item
解决外层循环的交叉迭代依赖
\end{compactitem}

该编译技术实现了基于Lamport算法的轻量级同步机制。简单的说，Lamport算法又称面包房算法，是一种先来先服务算法。
该算法跟很多银行采用的排队机制一样。客户到了银行，先领取一个服务号。
一旦某个窗口出现空闲，拥有最小服务号的客户就可以去空闲窗口办理业务。

更确切的，Lamport算法\footnote{Leslie
Lamport于1978年为分布式系统同步设计，Lamport同时是\LaTeX{}的作者，仰慕！}利用事件排序方法，对要求访问临界资源的全部事件进行排序，
并且按照先来先服务的原则，对事件进行处理。
该算法规定\cite{Lamport78}，每个进程Pi，
在发送请求消息Request时，应该为它打上时间邮戳（Ti，i），其中Ti是进程Pi的逻辑时钟值，
而且在每个进程中都保持一个请求队列，队列中包含了按逻辑时钟排序的请求消息。Lamport
算法用以下五项规则定义：
\begin{compactitem}
\item
当进程
Pi要求访问某个资源时，该进程将请求消息挂在自己的请求队列中，也发送一个Request（Ti，i）消息给所有其他进程。
\item
当进程 Pj收到
Request（Ti，i）消息时，形成一个打上时间邮戳的Reply（Tj，j）消息，
将它放在自己的请求队列中。应该说明，若进程Pj收到Request（Ti，i）消息前，
也提出过对同一资源的访问请求，那么其时间邮戳应该比T（Ti，i）小。
\item
若满足以下两个条件，则允许进程Pi访问该资源：
Pi自身请求访问该资源的消息已经处于请求队列的最前面；
Pi已经接收到从其他所有进程发回的响应消息，这些消息上的邮戳时间晚于T（Ti，i）。
\item
为了释放该资源，Pi从自己的请求队列中消除请求消息，并发送一个打上时间邮戳的Release消息给其他所有进程。
\item
消息后，从自己的队列中消除Pi的Request（Ti，i）消息。
\end{compactitem}

这样，当每一个进程要访问一个共享资源时，本算法要求该进程发送3（N-1）个消息，其中（N-1）个Request消息，（N-1）个Reply消息，（N-1）个
Release消息。

另处，需要注意的是，该编译方法假设所有的线程单元不共享寄存器。交叉迭代寄存器依赖将被转化成交叉迭代内存依赖，
然后通过内存spill指令解决该依赖。而这里交叉迭代寄存器依赖是在编译期间发现的。
